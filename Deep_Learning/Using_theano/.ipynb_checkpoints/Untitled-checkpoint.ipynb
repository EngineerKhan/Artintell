{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using conjugate gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following codes will import the necessary python packages for this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class logisticregression(object):\n",
    "    def __init__(self,input, n_in, n_out):\n",
    "        self.theta = theano.shared(value=numpy.zeros(n_in * n_out + n_out, dtype = theano.config.floatX), name='theta', borrow = True)\n",
    "        self.W = self.theta[0:n_in * n_out].reshape((n_in, n_out))\n",
    "        self.b = self.theta[n_in * n_out:n_in * n_out+n_out]\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W)+self.b)\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        self.input = input\n",
    "    def negative_log_likelihood(self, y ):\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]),y])\n",
    "    def errors(self, y):\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError('y should have the same shape as the self.y_pred', 'y',y.type, 'y_pred',self.y_pred.type)\n",
    "        if y.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.y_pred, y ))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    def load_data(dataset):\n",
    "        data_dir, data_file = os.path.split(dataset)\n",
    "        if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "            new_path = os.path.join(os.path.split(__file__)[0],\"..\",\"data\", dataset)\n",
    "            if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "                dataset= new_path\n",
    "                \n",
    "        if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "            from six.moves import urllib\n",
    "            origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "                )\n",
    "            print ('Downloading data from %s '%origin)\n",
    "            urllib.request.urlretrieve(origin, dataset)\n",
    "            \n",
    "        print ('-----loading datasets')\n",
    "        with gzip.open(dataset, 'rb') as f:\n",
    "            try:\n",
    "                train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "            except:\n",
    "                train_set, valid_set, test_set = pickle.load(f)\n",
    "                \n",
    "    def cg_optimization_mnist(n_epochs = 50, mnist_pkl_gz='mnist.pkl.gz'):\n",
    "        datasets = load_data(mnist_pkl.gz)\n",
    "        train_set_x, train_set_y = datasets[0]\n",
    "        valid_set_x, valid_set_y = datasets[1]\n",
    "        test_set_x, test_set_y = datasets[2]\n",
    "        \n",
    "        batch_size = 600\n",
    "        n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        \n",
    "        n_in = 28 * 28\n",
    "        n_out = 10\n",
    "        \n",
    "        print '.... Building Model'\n",
    "        minibatch_offset = T.lscalar()\n",
    "        x = T.matrix()\n",
    "        y = T.ivector()\n",
    "    \n",
    "        classifier = logisticregression(input=x,n_in=28*28, n_out=10)\n",
    "        cost = classifier.negative_log_likelihood(y).mean()\n",
    "        test_model = theano.function(\n",
    "        [minibatch_offset],\n",
    "        classifier.errors(y),\n",
    "        givens = {\n",
    "                x:test_set_x[minibatch_offset:minibatch_offset + batch_size],\n",
    "                y:test_set_x[minibatch_offset:minibatch_offset + batch_size]\n",
    "                },\n",
    "        name = \"test\")\n",
    "        validate_model = theano.function(\n",
    "        [minibatch_offset],\n",
    "        classifier.errors(y),\n",
    "            givens = {\n",
    "                x:valid_set_x[minibatch_offset:minibatch_offset +batch_size],\n",
    "                y:valid_set_y[minibatch_offset:minibatch_offset + batch_size]\n",
    "            },name = \"validate\"\n",
    "        )\n",
    "        batch_cost = theano.function(\n",
    "        [minibatch_offset],\n",
    "        cost, \n",
    "        givens = {\n",
    "                x:train_set_x[minibatch_offset:minibatch_offset + batch_size],\n",
    "                y:train_set_x[minibatch_offset:minibatch_offset + batch_size]\n",
    "                \n",
    "            }, name = 'batch_cost')\n",
    "        batch_grad = theano.function(\n",
    "        [minibatch_offset],\n",
    "        T.grad(cost, classifier.theta),\n",
    "            givens = \n",
    "            {x:train_set[minibatch_offset: minibatch_offset + batch_size],\n",
    "            y: train_set[minibatch_offset: minibatch_offset + batch_size]},\n",
    "            name = \"batch_grad\"\n",
    "        )\n",
    "        \n",
    "    def train_fn(theta_value):\n",
    "        classifier.theta.set_value(theta_value, borrow=True)\n",
    "        train_losses = [batch_cost(i * batch_size) for i in range(n_train_batches)]\n",
    "        return numpy.mean(train_losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
