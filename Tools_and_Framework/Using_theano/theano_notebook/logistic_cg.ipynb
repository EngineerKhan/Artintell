{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using conjugate gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following codes will import the necessary python packages for this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimising using the scipy.optimize.fmin_cg\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-692aad26a68d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mlogisticregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'theta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-692aad26a68d>\u001b[0m in \u001b[0;36mlogisticregression\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     best_w_b = scipy.optimize.fmin_cg(\n\u001b[1;32m    125\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_in' is not defined"
     ]
    }
   ],
   "source": [
    "class logisticregression(object):\n",
    "    def __init__(self,input, n_in, n_out):\n",
    "        self.theta = theano.shared(value=numpy.zeros(n_in * n_out + n_out, dtype = theano.config.floatX), name='theta', borrow = True)\n",
    "        self.W = self.theta[0:n_in * n_out].reshape((n_in, n_out))\n",
    "        self.b = self.theta[n_in * n_out:n_in * n_out+n_out]\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W)+self.b)\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        self.input = input\n",
    "    def negative_log_likelihood(self, y ):\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]),y])\n",
    "    def errors(self, y):\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError('y should have the same shape as the self.y_pred', 'y',y.type, 'y_pred',self.y_pred.type)\n",
    "        if y.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.y_pred, y ))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    def load_data(dataset):\n",
    "        data_dir, data_file = os.path.split(dataset)\n",
    "        if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "            new_path = os.path.join(os.path.split(__file__)[0],\"..\",\"data\", dataset)\n",
    "            if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "                dataset= new_path\n",
    "                \n",
    "        if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "            from six.moves import urllib\n",
    "            origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "                )\n",
    "            print ('Downloading data from %s '%origin)\n",
    "            urllib.request.urlretrieve(origin, dataset)\n",
    "            \n",
    "        print ('-----loading datasets')\n",
    "        with gzip.open(dataset, 'rb') as f:\n",
    "            try:\n",
    "                train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "            except:\n",
    "                train_set, valid_set, test_set = pickle.load(f)\n",
    "                \n",
    "    def cg_optimization_mnist(n_epochs = 50, mnist_pkl_gz='mnist.pkl.gz'):\n",
    "        datasets = load_data(mnist_pkl.gz)\n",
    "        train_set_x, train_set_y = datasets[0]\n",
    "        valid_set_x, valid_set_y = datasets[1]\n",
    "        test_set_x, test_set_y = datasets[2]\n",
    "        \n",
    "        batch_size = 600\n",
    "        n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "        \n",
    "        n_in = 28 * 28\n",
    "        n_out = 10\n",
    "        \n",
    "        print '.... Building Model'\n",
    "        minibatch_offset = T.lscalar()\n",
    "        x = T.matrix()\n",
    "        y = T.ivector()\n",
    "    \n",
    "        classifier = logisticregression(input=x,n_in=28*28, n_out=10)\n",
    "        cost = classifier.negative_log_likelihood(y).mean()\n",
    "        test_model = theano.function(\n",
    "        [minibatch_offset],\n",
    "        classifier.errors(y),\n",
    "        givens = {\n",
    "                x:test_set_x[minibatch_offset:minibatch_offset + batch_size],\n",
    "                y:test_set_x[minibatch_offset:minibatch_offset + batch_size]\n",
    "                },\n",
    "        name = \"test\")\n",
    "        validate_model = theano.function(\n",
    "        [minibatch_offset],\n",
    "        classifier.errors(y),\n",
    "            givens = {\n",
    "                x:valid_set_x[minibatch_offset:minibatch_offset +batch_size],\n",
    "                y:valid_set_y[minibatch_offset:minibatch_offset + batch_size]\n",
    "            },name = \"validate\"\n",
    "        )\n",
    "        batch_cost = theano.function(\n",
    "        [minibatch_offset],\n",
    "        cost, \n",
    "        givens = {\n",
    "                x:train_set_x[minibatch_offset:minibatch_offset + batch_size],\n",
    "                y:train_set_x[minibatch_offset:minibatch_offset + batch_size]\n",
    "                \n",
    "            }, name = 'batch_cost')\n",
    "        batch_grad = theano.function(\n",
    "        [minibatch_offset],\n",
    "        T.grad(cost, classifier.theta),\n",
    "            givens = \n",
    "            {x:train_set[minibatch_offset: minibatch_offset + batch_size],\n",
    "            y: train_set[minibatch_offset: minibatch_offset + batch_size]},\n",
    "            name = \"batch_grad\"\n",
    "        )\n",
    "        \n",
    "    def train_fn(theta_value):\n",
    "        classifier.theta.set_value(theta_value, borrow=True)\n",
    "        train_losses = [batch_cost(i * batch_size) for i in range(n_train_batches)]\n",
    "        return numpy.mean(train_losses)\n",
    "    \n",
    "    def train_fn_grad(theta_values):\n",
    "        classifier.theta.set_value(theta_value, borrow=True)\n",
    "        grad = batch_grad(0)\n",
    "        for i in range(1, n_train_batches):\n",
    "            grad += batch_grad(i * batch_size)\n",
    "        return grad / n_train_batches\n",
    "    \n",
    "    validation_scores = [numpy.inf, 0]\n",
    "    \n",
    "    def callback(theta_value):\n",
    "        classifier.theta.set_value(theta_value, borrow=True)\n",
    "        validation_losses = [validate_model(i * batch_size) for i in range(n_valid_batches)]\n",
    "        this_validation_loss = np.mean(validation_losses)\n",
    "        print('validation error %f %%'%(this_validation_loss * 100.,))\n",
    "        \n",
    "        if this_validation_loss < validation_scores[0]:\n",
    "            validation_scores[0] = this_validation_loss\n",
    "            test_losses = [test_model(i * batch_size)\n",
    "                          for i in range(n_test_batches)]\n",
    "            validation_scores[1] = numpy.mean(test_losses)\n",
    "            \n",
    "    import scipy.optimize\n",
    "    print (\"Optimising using the scipy.optimize.fmin_cg\")\n",
    "    start_w_b = timeit.default_timer()\n",
    "    best_w_b = scipy.optimize.fmin_cg(\n",
    "    f = train_fn,\n",
    "        x0 = numpy.zeros((n_in + 1)* n_out, dtype=x.dtype),\n",
    "        fprime = train_fn_grad,\n",
    "        callback=callback,\n",
    "        disp = 0,\n",
    "        maxiter = n_epochs\n",
    "        \n",
    "    )\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\n",
    "    ('Optimising Complete with the best Validation score of %f %%, with '\n",
    "        'test performance %f %%'\n",
    "    )% (validation_scores[0] * 100., validation_scores[1] * 100.)\n",
    "        \n",
    "    )\n",
    "    print >> sys.stderr, ('the code for the file ' + os.path.split(__file__)[1] + 'ran for %.1fs'%((end_time - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ = '__main__':\n",
    "    cg_optimization_mnist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
